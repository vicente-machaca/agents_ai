{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firt of all, create the template using the comands here:\n",
    "https://e2b.dev/docs/guide/custom-sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your API keys or save them to .env file.\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# TODO: Get your OpenAI API key\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# TODO: Get your E2B API key from https://e2b.dev/docs\n",
    "E2B_API_KEY = os.getenv(\"E2B_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is '.dockerenv' directory? False\n",
      "Is '.e2b' directory? False\n",
      "Is 'bin' directory? False\n",
      "Is 'boot' directory? True\n",
      "Is 'code' directory? True\n",
      "Is 'dev' directory? True\n",
      "Is 'etc' directory? True\n",
      "Is 'home' directory? True\n",
      "Is 'lib' directory? False\n",
      "Is 'lib32' directory? False\n",
      "Is 'lib64' directory? False\n",
      "Is 'libx32' directory? False\n",
      "Is 'lost+found' directory? True\n",
      "Is 'media' directory? True\n",
      "Is 'mnt' directory? True\n",
      "Is 'opt' directory? True\n",
      "Is 'proc' directory? True\n",
      "Is 'root' directory? True\n",
      "Is 'run' directory? True\n",
      "Is 'sbin' directory? False\n",
      "Is 'srv' directory? True\n",
      "Is 'swap' directory? True\n",
      "Is 'sys' directory? True\n",
      "Is 'tmp' directory? True\n",
      "Is 'usr' directory? True\n",
      "Is 'var' directory? True\n"
     ]
    }
   ],
   "source": [
    "from e2b import Sandbox                                                     \n",
    "                                                                            \n",
    "# Start sandbox                                                             \n",
    "sandbox = Sandbox(template=\"vicente-sandbox\")                               \n",
    "                                                                            \n",
    "# List the root directory\n",
    "content = sandbox.filesystem.list(\"/\")  \n",
    "for item in content:\n",
    "    print(f\"Is '{item.name}' directory?\", item.is_dir)                                 \n",
    "                                                                            \n",
    "# Close sandbox once done                                                   \n",
    "sandbox.close()                                                             \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a small data science analysis on E2B sandbox. I previosly built the container according to e2b.DockerFile.\n",
    "- I send the dataset and a python script\n",
    "- I request to run the script\n",
    "- I print and download the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your API keys or save them to .env file.\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# TODO: Get your OpenAI API key\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# TODO: Get your E2B API key from https://e2b.dev/docs\n",
    "E2B_API_KEY = os.getenv(\"E2B_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Employee_ID  Age  ... Sleep_Quality         Region\n",
      "0     EMP0001   32  ...          Good         Europe\n",
      "1     EMP0002   40  ...          Good           Asia\n",
      "2     EMP0003   59  ...          Poor  North America\n",
      "3     EMP0004   27  ...          Poor         Europe\n",
      "4     EMP0005   49  ...       Average  North America\n",
      "5     EMP0006   59  ...       Average  South America\n",
      "6     EMP0007   31  ...          Poor           Asia\n",
      "7     EMP0008   42  ...       Average  North America\n",
      "8     EMP0009   56  ...          Poor         Europe\n",
      "9     EMP0010   30  ...          Poor  North America\n",
      "\n",
      "[10 rows x 20 columns]\n",
      "Figure save: histogram.png\n",
      "Is '.bash_logout' directory? False\n",
      "Is '.bashrc' directory? False\n",
      "Is '.cache' directory? True\n",
      "Is '.config' directory? True\n",
      "Is '.profile' directory? False\n",
      "Is 'histogram.png' directory? False\n",
      "Is 'remote_work.csv' directory? False\n",
      "Is 'remote_work.py' directory? False\n"
     ]
    }
   ],
   "source": [
    "from e2b import Sandbox                                                     \n",
    "                                                                            \n",
    "# Start sandbox     \n",
    "# It seems that defining working directory with cwd is not working                                                        \n",
    "# sandbox = Sandbox(template=\"data-science-sandbox\", cwd=\"/code\" )         \n",
    "# Defalt working directory: /home/user                       \n",
    "sandbox = Sandbox(template=\"data-science-sandbox\")\n",
    "\n",
    "# uploading the dataset. Params: path to local file                         \n",
    "with open(\"remote_work.csv\", \"rb\") as f:\n",
    "    remote_path = sandbox.upload_file(f)     \n",
    "\n",
    "# uploading the source code \n",
    "with open(\"remote_work.py\", \"rb\") as f:\n",
    "    remote_path = sandbox.upload_file(f)                          \n",
    "\n",
    "# start process\n",
    "python_exec = sandbox.process.start(\"python remote_work.py\")  \n",
    "python_exec.wait()\n",
    "print(python_exec.stdout)\n",
    "\n",
    "# list files\n",
    "content = sandbox.filesystem.list(\"/home/user\")  \n",
    "for item in content:\n",
    "    print(f\"Is '{item.name}' directory?\", item.is_dir)   \n",
    "\n",
    "# Download result. Params: path to remote file\n",
    "file_in_bytes = sandbox.download_file(\"/home/user/histogram.png\")  \n",
    "# Save file to local filesystem\n",
    "with open(\"histogram_from_sandbox.png\", \"wb\") as f:  \n",
    "    f.write(file_in_bytes) \n",
    "                                                                            \n",
    "# Close sandbox once done                                                   \n",
    "sandbox.close()                                                             \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration with OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example will create the python code using a LLM, then we are going run the code in a sandbox provided by E2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    messages=[ \n",
    "    {\"role\": \"system\", \"content\": \"You are a python software developper.\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"Generate the content of a Python script, give me only the source code. The code must perform the following actions:\n",
    "        (1) read a file named remote_work.csv\n",
    "        (2) print columns names and its descriptions\n",
    "        (3) print the number of samples (rows - 1)\n",
    "        (4) remove null samples\n",
    "        (5) plot the distribution by the second column\n",
    "        Use libraries like pandas, numpy and malplotlib and return the results in this format:\n",
    "        {\n",
    "            \"description\": <your description of code>,\n",
    "            \"source_code\": <python code>\n",
    "        }\n",
    "        \"\"\"},\n",
    "    ]\n",
    ")\n",
    "'''completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    messages=[ \n",
    "    {\"role\": \"system\", \"content\": \"You are a python software developper.\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"Generate the content of a Python script, give me only the source code. The code must perform the following actions:\n",
    "        (1) read a file named remote_work.csv\n",
    "        (2) print columns names and its descriptions\n",
    "        (3) print the number of samples (rows - 1)\n",
    "        (4) remove null samples\n",
    "        (5) plot the distribution by the second column\n",
    "        Use libraries like pandas, numpy and malplotlib\n",
    "        \"\"\"},\n",
    "    ]\n",
    ")'''\n",
    "\n",
    "# show the LLM response\n",
    "result = completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"description\": \"This Python script reads a CSV file named 'remote_work.csv', prints the column names and their descriptions, prints the number of non-header samples, removes any rows with null values, and plots the distribution based on the second column of the dataset. It utilizes pandas for data manipulation, numpy for handling numerical operations, and matplotlib for plotting the distribution.\",\n",
      "    \"source_code\": \"import pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Read the 'remote_work.csv' file\\ndf = pd.read_csv('remote_work.csv')\\n\\n# Print column names and descriptions (assuming the file includes descriptions)\\n# This example assumes descriptions are in the second row, which is unusual and might need modification\\ncolumn_descriptions = df.iloc[0]\\nfor column, description in column_descriptions.items():\\n    print(f'Column: {column}, Description: {description}')\\n\\n# Print the number of samples (excluding the header row)\\n# If descriptions are in the second row, adjust row count accordingly\\nprint(f'Number of samples: {len(df) - 1}')\\n\\n# Remove null samples\\nfiltered_df = df.dropna()\\n\\n# Plot the distribution by the second column\\n# Assuming the second column is numeric for plot to work. Adjust as necessary.\\nsecond_column_name = df.columns[1]\\nplt.figure(figsize=(10, 6))\\nplt.hist(filtered_df[second_column_name], bins=30, color='skyblue', edgecolor='black')\\nplt.title(f'Distribution of {second_column_name}')\\nplt.xlabel(second_column_name)\\nplt.ylabel('Frequency')\\nplt.show()\\n\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "print(python_code)\n",
    "print(  )\n",
    "\n",
    "\n",
    "file = open('remote_work_generated.py', 'w')\n",
    "file.write(python_code)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
